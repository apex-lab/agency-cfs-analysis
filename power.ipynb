{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc549585",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import statsmodels.stats.power as smp\n",
    "from scipy.stats import ttest_1samp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from util.preprocessing import calc_overest_means, huber_mean\n",
    "from util.io import load_osf_binding_dataset\n",
    "from util.simulation import DataSimulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "362decb0-290c-4147-bc2a-fd4b93aec213",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_main = 0.01\n",
    "alpha_inter = 0.05\n",
    "p_aware = 0.05\n",
    "n_simulations = 10000\n",
    "cohens_d = 0.451 # meta-analytic effect size DOI:10.1163/22134468-20191150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0ea6060",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0files [00:00, ?files/s]\n",
      "  0%|                                           | 0.00/4.06M [00:00<?, ?bytes/s]\u001b[A\n",
      "  5%|█▋                                 | 197k/4.06M [00:00<00:01, 1.94Mbytes/s]\u001b[A\n",
      "100%|██████████████████████████████████| 4.06M/4.06M [00:00<00:00, 18.2Mbytes/s]\u001b[A\n",
      "1files [00:05,  5.54s/files]\n"
     ]
    }
   ],
   "source": [
    "# load n = 192 intentional binding dataset from OSF\n",
    "# reported in https://doi.org/10.31234/osf.io/4z2rj\n",
    "df = load_osf_binding_dataset() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bf8fa43-9308-445c-81a0-6ad83024a0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean difference (ms):  25.669576797923014\n",
      "Within-subject standard deviation (trial):  92.78735221092478\n",
      "Within-subject standard deviation (block mean):  14.670968552139124\n",
      "Within-subject standard deviation (block mean):  20.74788269958432\n",
      "Between-subject standard deviation:  78.78551687863724\n",
      "6.49% of the variance is within-subject.\n"
     ]
    }
   ],
   "source": [
    "# compute between and within subject variance estimates from OSF dataset\n",
    "sds = []\n",
    "operant_means = []\n",
    "operant_means = []\n",
    "baseline_means = []\n",
    "for sub in df.subject.unique():\n",
    "    df_sub = df[(df.subject == sub)]\n",
    "    baseline = df_sub.overest_ms[df_sub.operant == 0]\n",
    "    operant = df_sub.overest_ms[df_sub.operant == 1]\n",
    "    sds.append(baseline.std())\n",
    "    operant_means.append(huber_mean(operant))\n",
    "    baseline_means.append(huber_mean(baseline))\n",
    "baseline = np.array(baseline_means)\n",
    "operant = np.array(operant_means)\n",
    "diffs = (operant - baseline)\n",
    "sds = np.array(sds)\n",
    "\n",
    "sd_trial = np.mean(sds)\n",
    "sd_block = sd_trial / np.sqrt(40)\n",
    "sd_wi = np.sqrt(2*(sd_block**2))\n",
    "sd_total = np.std(diffs)\n",
    "sd_bw = np.sqrt(sd_total**2 - sd_wi**2)\n",
    "frac_wi = (sd_wi**2) / (sd_total**2)\n",
    "mu = np.mean(diffs)\n",
    "print('Mean difference (ms): ', mu)\n",
    "print('Within-subject standard deviation (trial): ', sd_trial)\n",
    "print('Within-subject standard deviation (block mean): ', sd_block)\n",
    "print('Within-subject standard deviation (block mean): ', sd_wi)\n",
    "print('Between-subject standard deviation: ', sd_bw)\n",
    "print('%.02f%% of the variance is within-subject.'%(100*frac_wi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "489f0c8e-bebd-4eae-a385-071fcb047b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's d for difference-in-differences is 0.44\n"
     ]
    }
   ],
   "source": [
    "## adjust Cohen's d for interaction by doubling within-subject variance\n",
    "d_interaction = cohens_d / np.sqrt(1 + frac_wi)\n",
    "print(\"Cohen's d for difference-in-differences is %.02f\"%d_interaction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60b77cf-b85b-472d-a2ed-1a50ff817e96",
   "metadata": {},
   "source": [
    "(The above works because we assume effect size in the masked conditions is 0 if $H_0$ is true for the main effect, so the only additional variance in the interaction given $H_0$ is a doubling of the within-subject variance.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de818397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size needed for main effect: 80\n",
      "Sample size needed for interaction effect: 58\n",
      "So sample size is: 80\n"
     ]
    }
   ],
   "source": [
    "# pick sample size to achieve target power for main effect\n",
    "def sample_size_calculation(d, alpha):\n",
    "    power_analysis = smp.TTestPower()\n",
    "    sample_size = power_analysis.solve_power(\n",
    "        effect_size = d, \n",
    "        power = 0.95, \n",
    "        alpha = alpha, \n",
    "        alternative = 'larger'\n",
    "    )\n",
    "    sample_size = np.round(sample_size).astype(int) \n",
    "    return sample_size\n",
    "ss_main = sample_size_calculation(cohens_d, alpha_main)\n",
    "print('Sample size needed for main effect:', ss_main)\n",
    "ss_iter = sample_size_calculation(d_interaction, alpha_inter)\n",
    "print('Sample size needed for interaction effect:', ss_iter)\n",
    "sample_size = np.max([ss_main, ss_iter])\n",
    "print('So sample size is:', ss_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f460c5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(p_aware, n_subjects, seed = None):\n",
    "    '''\n",
    "    Simulates data that is null for the masked conditions, and has a nonzero\n",
    "    effect for the unmasked conditions.\n",
    "    \n",
    "    All the DataFrame junk going on inside DataSimulator makes this extremely slow\n",
    "    (we're talking 40+ times longer than if we just did this in numpy),\n",
    "    but this way we get to use the same functions we'll use to analyze the real data.\n",
    "    '''\n",
    "    # simulate data\n",
    "    sim = DataSimulator( \n",
    "        n_trials = 40, # per block\n",
    "        effect_size_ms = mu,\n",
    "        sd_pop = sd_bw,\n",
    "        sd_sub = sd_trial\n",
    "    )\n",
    "    rng = np.random.default_rng(seed)\n",
    "    dfs = [sim.simulate_subject(p_aware, rng) for sub in range(n_subjects)]\n",
    "    means = [calc_overest_means(df) for df in dfs]\n",
    "    df = pd.DataFrame(means)\n",
    "    # compute paired differences\n",
    "    delta_masked = df['masked operant'] - df['masked baseline']\n",
    "    delta_unmasked = df['unmasked operant'] - df['unmasked baseline']\n",
    "    delta2 = delta_masked - delta_unmasked\n",
    "    # test for main effect of interest\n",
    "    res = ttest_1samp(delta_masked, popmean = 0, alternative = 'greater')\n",
    "    reject = res.pvalue < alpha_main\n",
    "    return reject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0b49311",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:   11.8s\n",
      "[Parallel(n_jobs=-1)]: Done 188 tasks      | elapsed:   48.8s\n",
      "[Parallel(n_jobs=-1)]: Done 438 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 788 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1238 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1788 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2438 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=-1)]: Done 3188 tasks      | elapsed: 13.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4038 tasks      | elapsed: 17.2min\n",
      "[Parallel(n_jobs=-1)]: Done 4988 tasks      | elapsed: 21.1min\n",
      "[Parallel(n_jobs=-1)]: Done 6038 tasks      | elapsed: 25.3min\n",
      "[Parallel(n_jobs=-1)]: Done 7188 tasks      | elapsed: 30.0min\n",
      "[Parallel(n_jobs=-1)]: Done 8438 tasks      | elapsed: 35.1min\n",
      "[Parallel(n_jobs=-1)]: Done 9788 tasks      | elapsed: 40.6min\n",
      "[Parallel(n_jobs=-1)]: Done 10000 out of 10000 | elapsed: 41.5min finished\n"
     ]
    }
   ],
   "source": [
    "## find combined false positive rate by simulation\n",
    "pfunc = delayed(simulate)\n",
    "parallel = Parallel(n_jobs = -1, verbose = 1)\n",
    "output = parallel(pfunc(p_aware, sample_size, i) for i in range(n_simulations))\n",
    "output = np.array(output)\n",
    "fpr = output.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e2d33a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The false positive is rate = 3.79% at p_aware = 0.05...\n",
      "Approximately 1.00% due to statistical error,\n",
      "plus 2.79% due to residual awareness.\n",
      "\n",
      "To be sure p_aware is less than 0.05, then accuracy must be less than 52.50%.\n"
     ]
    }
   ],
   "source": [
    "print('The false positive is rate = %.02f%% at p_aware = %.02f...'%(100*fpr, p_aware))\n",
    "print('Approximately %.02f%% due to statistical error,'%(100*alpha_main))\n",
    "print('plus %.02f%% due to residual awareness.'%(100*(fpr - alpha_main)))\n",
    "\n",
    "accuracy = .5*(1 - p_aware) + 1.*p_aware\n",
    "print('\\nTo be sure p_aware is less than %.02f,' \\\n",
    "    ' then accuracy must be less than %.02f%%.'%(p_aware, 100*accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73318c67-2ed8-4f1a-b5c7-ca038ecd664a",
   "metadata": {},
   "source": [
    "The originally proposed analysis, using $t$-tests, was replaced following interim peer-review. Consequently, we performed the simulations below to verify that the new tests have sufficient statistical power:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "018a1c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=-1)]: Done 188 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 438 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 788 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1238 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1788 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2438 tasks      | elapsed: 13.8min\n",
      "[Parallel(n_jobs=-1)]: Done 3188 tasks      | elapsed: 18.2min\n",
      "[Parallel(n_jobs=-1)]: Done 4038 tasks      | elapsed: 23.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4988 tasks      | elapsed: 28.5min\n",
      "[Parallel(n_jobs=-1)]: Done 6038 tasks      | elapsed: 34.6min\n",
      "[Parallel(n_jobs=-1)]: Done 7188 tasks      | elapsed: 41.2min\n",
      "[Parallel(n_jobs=-1)]: Done 8438 tasks      | elapsed: 48.2min\n",
      "[Parallel(n_jobs=-1)]: Done 9788 tasks      | elapsed: 55.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power for main effect at alpha = 0.010 is 0.984\n",
      "Power for interaction effect at alpha = 0.050 is 0.982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 10000 out of 10000 | elapsed: 57.1min finished\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import norm\n",
    "import warnings\n",
    "\n",
    "def simulate_mixedfx(n_subjects, seed = None):\n",
    "\n",
    "    # simulate data\n",
    "    sim = DataSimulator( \n",
    "        n_trials = 40, # per block\n",
    "        effect_size_ms = mu,\n",
    "        sd_pop = sd_bw,\n",
    "        sd_sub = sd_trial\n",
    "    )\n",
    "    rng = np.random.default_rng(seed)\n",
    "    dfs = [sim.simulate_subject(0., rng) for sub in range(n_subjects)]\n",
    "    [df.insert(0, 'subject', i) for i, df in enumerate(dfs)]\n",
    "    df = pd.concat(dfs)\n",
    "    \n",
    "    # test for main and interaction effect with multilevel model\n",
    "    mod = smf.mixedlm('overest_t ~ operant*masked', df, groups = df['subject'])\n",
    "    warnings.filterwarnings('ignore')\n",
    "    mdf = mod.fit()\n",
    "    # and extract one-tailed p-values for preregistered comparisons\n",
    "    z = mdf.tvalues # really Z-values\n",
    "    p_binding = norm.sf(z['operant[T.True]']) # upper tailed\n",
    "    p_interaction = norm.cdf(z['operant[T.True]:masked[T.True]']) # lower tailed\n",
    "\n",
    "    # return whether nulls rejected at specified significance levels \n",
    "    return p_binding < alpha_main, p_interaction < alpha_inter\n",
    "\n",
    "## power analysis by simulation for mixed effects model\n",
    "pfunc = delayed(simulate_mixedfx)\n",
    "parallel = Parallel(n_jobs = -1, verbose = 1)\n",
    "output = parallel(pfunc(sample_size, i) for i in range(n_simulations))\n",
    "rejections = np.array(output)\n",
    "power = rejections.mean(0)\n",
    "print('Power for main effect at alpha = %.03f is %.03f'%(alpha_main, power[0]))\n",
    "print('Power for interaction effect at alpha = %.03f is %.03f'%(alpha_inter, power[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cffaf97-de1a-4741-a137-b9937155549b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:   36.0s\n",
      "[Parallel(n_jobs=-1)]: Done 188 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 438 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=-1)]: Done 788 tasks      | elapsed: 11.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1238 tasks      | elapsed: 18.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1788 tasks      | elapsed: 26.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2438 tasks      | elapsed: 35.9min\n",
      "[Parallel(n_jobs=-1)]: Done 3188 tasks      | elapsed: 47.3min\n",
      "[Parallel(n_jobs=-1)]: Done 4038 tasks      | elapsed: 59.9min\n",
      "[Parallel(n_jobs=-1)]: Done 4988 tasks      | elapsed: 74.0min\n",
      "[Parallel(n_jobs=-1)]: Done 6038 tasks      | elapsed: 89.5min\n",
      "[Parallel(n_jobs=-1)]: Done 7188 tasks      | elapsed: 106.6min\n",
      "[Parallel(n_jobs=-1)]: Done 8438 tasks      | elapsed: 125.3min\n",
      "[Parallel(n_jobs=-1)]: Done 9788 tasks      | elapsed: 146.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False positive rate = 0.039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 10000 out of 10000 | elapsed: 149.7min finished\n"
     ]
    }
   ],
   "source": [
    "def simulate_mixedfx_null(n_subjects, seed = None):\n",
    "\n",
    "    # simulate null data with spurious aware trials\n",
    "    sim = DataSimulator( \n",
    "        n_trials = 40, # per block\n",
    "        effect_size_ms = mu,\n",
    "        sd_pop = sd_bw,\n",
    "        sd_sub = sd_trial\n",
    "    )\n",
    "    rng = np.random.default_rng(seed)\n",
    "    dfs = [sim.simulate_subject(p_aware, rng) for sub in range(n_subjects)]\n",
    "    [df.insert(0, 'subject', i) for i, df in enumerate(dfs)]\n",
    "    df = pd.concat(dfs)\n",
    "    \n",
    "    # test for main effect with multilevel model\n",
    "    data = df[df.masked] # only masked condition trials\n",
    "    mod = smf.mixedlm('overest_t ~ operant', data, groups = data['subject'])\n",
    "    warnings.filterwarnings('ignore')\n",
    "    mdf = mod.fit()\n",
    "    # and extract one-tailed p-value for preregistered comparison\n",
    "    z = mdf.tvalues # actually Z-values\n",
    "    p = norm.sf(z['operant[T.True]'])\n",
    "\n",
    "    # return whether null rejected at specified significance levels \n",
    "    return p < alpha_main\n",
    "\n",
    "## estimate effective false positive rate of mixed effects model\n",
    "pfunc = delayed(simulate_mixedfx_null)\n",
    "parallel = Parallel(n_jobs = -1, verbose = 1)\n",
    "output = parallel(pfunc(sample_size, i) for i in range(n_simulations))\n",
    "rejections = np.array(output)\n",
    "fpr = rejections.mean()\n",
    "print('False positive rate = %.03f'%fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9e86dda-3fbc-4fd1-83ad-1a83e171b3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The false positive is rate = 3.87% at p_aware = 0.05...\n",
      "Approximately 1.00% due to statistical error,\n",
      "plus 2.87% due to residual awareness.\n"
     ]
    }
   ],
   "source": [
    "print('The false positive is rate = %.02f%% at p_aware = %.02f...'%(100*fpr, p_aware))\n",
    "print('Approximately %.02f%% due to statistical error,'%(100*alpha_main))\n",
    "print('plus %.02f%% due to residual awareness.'%(100*(fpr - alpha_main)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446d90cd-7793-483c-a8eb-7995d5a40555",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
