{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc549585",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import statsmodels.stats.power as smp\n",
    "from scipy.stats import ttest_1samp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from util.preprocessing import calc_overest_means\n",
    "from util.simulation import DataSimulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e1837a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_main = 0.01\n",
    "alpha_inter = 0.05\n",
    "p_aware = 0.05\n",
    "n_simulations = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de818397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/johnv/anaconda3/envs/neuroforecasting/lib/python3.9/site-packages/scipy/stats/_continuous_distns.py:6832: RuntimeWarning: divide by zero encountered in _nct_sf\n",
      "  return np.clip(_boost._nct_sf(x, df, nc), 0, 1)\n"
     ]
    }
   ],
   "source": [
    "# pick sample size to achieve target power for main effect\n",
    "power_analysis = smp.TTestPower()\n",
    "sample_size = power_analysis.solve_power(\n",
    "    effect_size = 0.451, \n",
    "    power = 0.95, \n",
    "    alpha = alpha_main, \n",
    "    alternative = 'larger'\n",
    ")\n",
    "sample_size = np.round(sample_size).astype(int) \n",
    "print('Sample size:', sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f460c5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(p_aware, n_subjects, seed = None):\n",
    "    '''\n",
    "    Simulates data that is null for the masked conditions, and has a nonzero\n",
    "    effect for the unmasked conditions.\n",
    "    \n",
    "    All the DataFrame junk going on inside DataSimulator makes this way slower \n",
    "    but we get to use the same functions we'll use to analyze the real data this way.\n",
    "    '''\n",
    "    # simulate data\n",
    "    sim = DataSimulator( # use simulation params computed from n = 190 dataset\n",
    "        n_trials = 40, # reported at https://doi.org/10.31234/osf.io/4z2rj\n",
    "        effect_size_ms = 28.,\n",
    "        sd_pop = 76.,\n",
    "        sd_sub = 92.\n",
    "    )\n",
    "    rng = np.random.default_rng(seed)\n",
    "    dfs = [sim.simulate_subject(p_aware, rng) for sub in range(n_subjects)]\n",
    "    means = [calc_overest_means(df) for df in dfs]\n",
    "    df = pd.DataFrame(means)\n",
    "    # compute paired differences\n",
    "    delta_masked = df['masked operant'] - df['masked baseline']\n",
    "    delta_unmasked = df['unmasked operant'] - df['unmasked baseline']\n",
    "    delta2 = delta_masked - delta_unmasked\n",
    "    # test for main effect of interest\n",
    "    res = ttest_1samp(delta_masked, popmean = 0, alternative = 'greater')\n",
    "    masked = res.pvalue < alpha_main\n",
    "    # test for interaction effect\n",
    "    res = ttest_1samp(delta2, popmean = 0, alternative = 'less')\n",
    "    interaction = res.pvalue < alpha_inter # use nominal alpha, not adjusted\n",
    "    return masked, interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0b49311",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:   12.4s\n",
      "[Parallel(n_jobs=-1)]: Done 188 tasks      | elapsed:   53.6s\n",
      "[Parallel(n_jobs=-1)]: Done 438 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 788 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1238 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1788 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2438 tasks      | elapsed: 11.6min\n",
      "[Parallel(n_jobs=-1)]: Done 3188 tasks      | elapsed: 15.2min\n",
      "[Parallel(n_jobs=-1)]: Done 4038 tasks      | elapsed: 19.3min\n",
      "[Parallel(n_jobs=-1)]: Done 4988 tasks      | elapsed: 23.9min\n",
      "[Parallel(n_jobs=-1)]: Done 6038 tasks      | elapsed: 29.0min\n",
      "[Parallel(n_jobs=-1)]: Done 7188 tasks      | elapsed: 34.6min\n",
      "[Parallel(n_jobs=-1)]: Done 8438 tasks      | elapsed: 40.0min\n",
      "[Parallel(n_jobs=-1)]: Done 9788 tasks      | elapsed: 45.8min\n",
      "[Parallel(n_jobs=-1)]: Done 10000 out of 10000 | elapsed: 46.7min finished\n"
     ]
    }
   ],
   "source": [
    "## find combined false positive rate by simulation\n",
    "pfunc = delayed(simulate)\n",
    "parallel = Parallel(n_jobs = -1, verbose = 1)\n",
    "output = parallel(pfunc(p_aware, sample_size, i) for i in range(n_simulations))\n",
    "output = np.array(output)\n",
    "fpr = output[:, 0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e2d33a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The false positive is rate = 4.27% at p_aware = 0.05...\n",
      "Approximately 1.00% due to statistical error,\n",
      "plus 3.27% due to residual awareness.\n",
      "\n",
      "To be sure p_aware is less than 0.05, then accuracy must be less than 52.50%.\n"
     ]
    }
   ],
   "source": [
    "print('The false positive is rate = %.02f%% at p_aware = %.02f...'%(100*fpr, p_aware))\n",
    "print('Approximately %.02f%% due to statistical error,'%(100*alpha_main))\n",
    "print('plus %.02f%% due to residual awareness.'%(100*(fpr - alpha_main)))\n",
    "\n",
    "accuracy = .5*(1 - p_aware) + 1.*p_aware\n",
    "print('\\nTo be sure p_aware is less than %.02f,' \\\n",
    "    ' then accuracy must be less than %.02f%%.'%(p_aware, 100*accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e482f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power for detecting the interaction effect is 0.91.\n"
     ]
    }
   ],
   "source": [
    "power_interaction = output[:, 1].mean()\n",
    "print('Power for detecting the interaction effect is %.02f.'%power_interaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018a1c0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
